<!DOCTYPE html>
<html>

<head>

<meta name="keywords" content="JavaScript, WebRTC, Depth Stream" />
<meta name="description" content="WebRTC codelab" />
<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1">

<title>WebRTC codelab: step 3</title>

<style>
    body {
        font-family: Monospace;
        background-color: #000000;
        margin: 0px;
        overflow: hidden;
    }

    #info {
        color: #ffffff;

        font-family: Monospace;
        font-size: 13px;
        text-align: center;
        font-weight: bold;

        position: absolute;
        top: 0px; width: 100%;
        padding: 5px;
    }

    #local3DSence {
      position: absolute;
      width: 640px;
      height: 480px;
    }

    #remote3DSence {
      position: absolute;
      left: 650px;
      width: 640px;
      height: 480px;
    }

    a {

        color: #0040ff;

    }
</style>

</head>

<body>

  <video id="localVideo" autoplay muted style="display:none"></video>
  <video id="localDepthVideo" autoplay muted></video>
    <canvas id="rgbd_canvas" width="320" height="240"></canvas>
  <video id="remoteVideo" autoplay muted></video>
  <video id="remoteDepthVideo" autoplay muted></video>
    
  <div>
    <button id="startButton">Start</button>
    <button id="callButton">Call</button>
    <button id="hangupButton">Hang Up</button>
  </div>
  <div id="local3DSence"></div>
  <div id="remote3DSence"></div>
<script src="libs/three.min.js"></script>
<script src='libs/dat.gui.min.js'></script>
<script src="libs/Detector.js"></script>
<script src="libs/stats.min.js"></script>
<script id="vs" type="x-shader/x-vertex">

    uniform sampler2D map;

    uniform float width;
    uniform float height;
    uniform float nearClipping, farClipping;

    uniform float pointSize;
    uniform float zOffset;

    uniform float depthEncoding;

    varying vec2 vUv;

    const float XtoZ = 1.11146; // tan( 1.0144686 / 2.0 ) * 2.0;
    const float YtoZ = 0.83359; // tan( 0.7898090 / 2.0 ) * 2.0;

    const float max = 3000.;
    const float min = 150.;
    const float np = 512.;
    const float w = max;

    // Implement the depth decode scheme proposed in paper
    // "Adapting Standard Video Codecs for Depth Streaming"
    float decodeAdaptiveDepth(vec4 rgba) {
        float L = rgba.b;
        float Ha = rgba.g;
        float Hb = rgba.r;
        float p = np / w;

        float m = mod(floor( 4. * L / p - 0.5 ), 4.);
        float q;
        if (m == 0.) {
            q = p / 2. * Ha;
        } else if (m == 1.) {
            q = p / 2. * Hb;
        } else if (m == 2.) {
            q = p / 2. * (1. - Ha);
        } else if (m == 3.) {
            q = p / 2. * (1. - Hb);
        }

        float l = L - (mod(L - p / 8., p)) + p / 4. * m - p / 8.;

        float d = w * (l + q);
        if (d < min)
            return 1.0;
        else
            return (l + q);
        return 1.0;
    }

    // Implement the BIT2 scheme described in paper
    // "Adapting Standard Video Codecs for Depth Streaming"
    float decodeRawDepth(vec4 rgba) {
        float d = 255. * rgba.b * 256. +
                  255. * rgba.g * 4. + 
                  255. * rgba.r / 8.;
        if (d < min || d > w)
            return 1.0;
        else
            return d / w;
        return 1.0;
    }

    // Implement the equation (5) in paper
    // "3-D Video Representation Using Depth Maps"
    float decodeGrayscaleDepth(vec4 rgba) {
        float d = 1.0 / (rgba.b * (1.0 / min - 1.0 / max) + 1.0 / max);
        return d / max;
    }

    void main() {

        vUv = vec2( position.x / width, position.y / height );

        vec4 color = texture2D( map, vUv );

        float depth = 1.0;

        if (depthEncoding == 0.)
            depth = decodeGrayscaleDepth(color);
        else if (depthEncoding == 1.)
            depth = decodeAdaptiveDepth(color);
        else if (depthEncoding == 2.)
            depth = decodeRawDepth(color);

        // Projection code by @kcmic
        float z = depth * (farClipping - nearClipping) + nearClipping;

        vec4 pos = vec4(
            ( position.x / width - 0.5 ) * z * XtoZ,
            ( position.y / height - 0.5 ) * z * YtoZ,
            - z + zOffset,
            1.0);

        gl_PointSize = pointSize;
        gl_Position = projectionMatrix * modelViewMatrix * pos;

    }

</script>

<script id="fs" type="x-shader/x-fragment">

    uniform sampler2D map;
    uniform sampler2D rgbMap;
    uniform float enableRgbTexture;

    varying vec2 vUv;

    void main() {
        vec4 color = texture2D( rgbMap, vUv );
        gl_FragColor = vec4( color.r, color.g, color.b, smoothstep( 8000.0, -8000.0, gl_FragCoord.z / gl_FragCoord.w ) );
    }

</script>
<script>
var localStream, remoteStream, localPeerConnection, remotePeerConnection;
var localDepthStream, remoteDepthStream;

var localVideo = document.getElementById("localVideo");
var localDepthVideo = document.getElementById("localDepthVideo");
var remoteVideo = document.getElementById("remoteVideo");
var remoteDepthVideo = document.getElementById("remoteDepthVideo");

var container_width = 640, container_height = 480;
var localContainer = document.getElementById("local3DSence");
var remoteContainer = document.getElementById("remote3DSence");

var startButton = document.getElementById("startButton");
var callButton = document.getElementById("callButton");
var hangupButton = document.getElementById("hangupButton");
startButton.disabled = false;
callButton.disabled = true;
hangupButton.disabled = true;
startButton.onclick = start;
callButton.onclick = call;
hangupButton.onclick = hangup;

var stats = new Stats();
stats.domElement.style.position = 'absolute';
stats.domElement.style.bottom = '0px';
stats.domElement.style.left = '0px';
document.body.appendChild( stats.domElement );

var nearClipping = 150, farClipping = 3000;
var pointSize = 2;
var zOffset = 500;

function trace(text) {
  console.log((performance.now() / 1000).toFixed(3) + ": " + text);
}

function gotStream(stream){
  trace("Received local stream");
  localVideo.src = URL.createObjectURL(stream);
  localStream = stream;
  callButton.disabled = false;
  navigator.getUserMedia({audio:true, video: {'mandatory': {'depth': true}}}, gotDepthStream,
    function(error) {
      trace("navigator.getUserMedia error for depth stream: ", error);
    });
}

function gotDepthStream(stream){
  trace("Received local depth stream");
  localDepthVideo.src = URL.createObjectURL(stream);
  localDepthStream = stream;
  startRendering(localContainer, localDepthVideo, localVideo);
}

function start() {
  trace("Requesting local stream");
  startButton.disabled = true;
  navigator.getUserMedia = navigator.getUserMedia ||
    navigator.webkitGetUserMedia || navigator.mozGetUserMedia;
  navigator.getUserMedia({audio:true, video:true}, gotStream,
    function(error) {
      trace("navigator.getUserMedia error: ", error);
    });
}

function call() {
  callButton.disabled = true;
  hangupButton.disabled = false;
  trace("Starting call");

  if (localStream.getVideoTracks().length > 0) {
    trace('Using video device: ' + localStream.getVideoTracks()[0].label);
  }
  if (localStream.getAudioTracks().length > 0) {
    trace('Using audio device: ' + localStream.getAudioTracks()[0].label);
  }

  var servers = null;

  localPeerConnection = new webkitRTCPeerConnection(servers);
  trace("Created local peer connection object localPeerConnection");
  localPeerConnection.onicecandidate = gotLocalIceCandidate;

  remotePeerConnection = new webkitRTCPeerConnection(servers);
  trace("Created remote peer connection object remotePeerConnection");
  remotePeerConnection.onicecandidate = gotRemoteIceCandidate;
  remotePeerConnection.onaddstream = gotRemoteStream;

  localPeerConnection.addStream(localStream);
  localPeerConnection.addStream(localDepthStream);
  trace("Added localStream to localPeerConnection");
  localPeerConnection.createOffer(gotLocalDescription);
}

function gotLocalDescription(description){
  localPeerConnection.setLocalDescription(description);
  trace("Offer from localPeerConnection: \n" + description.sdp);
  remotePeerConnection.setRemoteDescription(description);
  remotePeerConnection.createAnswer(gotRemoteDescription);
}

function gotRemoteDescription(description){
  remotePeerConnection.setLocalDescription(description);
  trace("Answer from remotePeerConnection: \n" + description.sdp);
  localPeerConnection.setRemoteDescription(description);
}

function hangup() {
  trace("Ending call");
  localPeerConnection.close();
  remotePeerConnection.close();
  localPeerConnection = null;
  remotePeerConnection = null;
  hangupButton.disabled = true;
  callButton.disabled = false;
}

function gotRemoteStream(event){
  if (!remoteStream) {
    remoteStream = event.stream;
    remoteVideo.src = URL.createObjectURL(event.stream);
    trace("Received remote color stream");
  } else {
    remoteDepthStream = event.stream;
    remoteDepthVideo.src = URL.createObjectURL(event.stream);
    startRendering(remoteContainer, remoteDepthVideo, remoteVideo);
    trace("Received remote depth stream");
  }
  
}

function gotLocalIceCandidate(event){
  if (event.candidate) {
    remotePeerConnection.addIceCandidate(new RTCIceCandidate(event.candidate));
    trace("Local ICE candidate: \n" + event.candidate.candidate);
  }
}

function gotRemoteIceCandidate(event){
  if (event.candidate) {
    localPeerConnection.addIceCandidate(new RTCIceCandidate(event.candidate));
    trace("Remote ICE candidate: \n " + event.candidate.candidate);
  }
}

function startRendering(container, depthVideo, rgbVideo) {
    var camera = new THREE.PerspectiveCamera( 50, container_width / container_height, 1, 10000 );
    camera.position.set( 0, 0, 500 );

    var scene = new THREE.Scene();
    var center = new THREE.Vector3();
    center.z = - 1000;

    var depth_canvas = document.createElement( 'canvas');
    depth_canvas.width = 320;
    depth_canvas.height = 240;
    var depth_context = depth_canvas.getContext('2d');
    var color_canvas = document.createElement( 'canvas');
    color_canvas.width = 640;
    color_canvas.height = 480;
    var color_context = color_canvas.getContext('2d');
    var rgbd_canvas = document.getElementById('rgbd_canvas');
    rgbd_canvas.display = "block";
    rgbd_canvas.width = 320;
    rgbd_canvas.height = 240;
    var rgbd_context = rgbd_canvas.getContext('2d');
    var depth_texture;
    var color_texture;
    var geometry;
    var material;

    function VideoReady() {
        depth_texture = new THREE.Texture( depth_canvas );
        color_texture = new THREE.Texture( rgbd_canvas );

        var width = 320, height = 240;

        geometry = new THREE.Geometry();

        for ( var i = 0, l = width * height; i < l; i ++ ) {

            var vertex = new THREE.Vector3();
            vertex.x = ( i % width );
            vertex.y = Math.floor( i / width );

            geometry.vertices.push( vertex );

        }

        material = new THREE.ShaderMaterial( {

            uniforms: {

                "map": { type: "t", value: depth_texture },
                "rgbMap": {type: "t", value: color_texture },
                "width": { type: "f", value: width },
                "height": { type: "f", value: height },
                "nearClipping": { type: "f", value: nearClipping },
                "farClipping": { type: "f", value: farClipping },
                "depthEncoding": { type: "f", value: 0},
                "pointSize": { type: "f", value: pointSize },
                "zOffset": { type: "f", value: zOffset }

            },
            vertexShader: document.getElementById( 'vs' ).textContent,
            fragmentShader: document.getElementById( 'fs' ).textContent,
            depthTest: false, depthWrite: false,
            transparent: true

        } );

        var mesh = new THREE.ParticleSystem( geometry, material );
        mesh.position.x = 0;
        mesh.position.y = 0;
        scene.add( mesh );

        var gui = new dat.GUI({autoPlace: false});
        container.appendChild(gui.domElement);
        gui.domElement.style.position = "absolute";
        gui.domElement.style.top = "0px";
        gui.domElement.style.right = "5px";
        gui.add( material.uniforms.nearClipping, 'value', 1, 10000, 1.0 ).name( 'nearClipping' );
        gui.add( material.uniforms.farClipping, 'value', 1, 10000, 1.0 ).name( 'farClipping' );
        gui.add( material.uniforms.pointSize, 'value', 1, 10, 1.0 ).name( 'pointSize' );
        gui.add( material.uniforms.zOffset, 'value', 0, 4000, 1.0 ).name( 'zOffset' );
        gui.add( material.uniforms.depthEncoding, 'value', { Grayscale: 0, Adaptive: 1, Raw: 2 } ).name('Depth Encoding');
        gui.close();

        var intervalId = setInterval(drawVideo, 1000 / 30 );
        animate();

    }

    var renderer = new THREE.WebGLRenderer();
    renderer.setSize( container_width, container_height );
    container.appendChild( renderer.domElement );

    var mouse = new THREE.Vector3( 0, 0, 1 );

    window.addEventListener( 'mousemove', onDocumentMouseMove, false );

    requestAnimationFrame(VideoReady);

    var cameraParams = {
        d: {
            cx: 160,
            cy: 120,
            fx: 224.501999,
            fy: 230.494003
        },
        rgb: {
            cx: 320.000000,
            cy: 240.000000,
            fx: 587.452087,
            fy: 600.674561
        },
        r: {
            r11:0.999711, r12:0.001065, r13:-0.024007, r21:0.001455, r22:-0.999867, r23:0.016223, r31:0.023986, r32:0.016253, r33:0.999580
        },
        t: {
            x: 0.026000, y:-0.000508, z:-0.000863
        }
  };

  function caliberate() {
      depth_context.drawImage(depthVideo, 0, 0, depth_canvas.width, depth_canvas.height);
      color_context.drawImage(rgbVideo, 0, 0, color_canvas.width, color_canvas.height);
      var colorImageData = color_context.getImageData(0, 0, color_canvas.width, color_canvas.height);
      var depthImageData = depth_context.getImageData(0, 0, depth_canvas.width, depth_canvas.height);
      var rgbdImageData = rgbd_context.getImageData(0, 0, rgbd_canvas.width, rgbd_canvas.height);
      var arr_index = 0;
      for (var i = 0 ; i < depth_canvas.height; ++i) {
          for (var j = 0; j < depth_canvas.width; ++j, arr_index += 4) {
              var dx = j;
              var dy = i;
              var r = depthImageData.data[arr_index];
              var g = depthImageData.data[arr_index + 1];
              var b = depthImageData.data[arr_index + 2];
              var d = b * 256. +
                  g * 4. + 
                  r / 8.;
              var dz = d / 1000.0; // depth value to meters
              /*
              P3D.x = (x_d - cx_d) * depth(x_d,y_d) / fx_d
              P3D.y = (y_d - cy_d) * depth(x_d,y_d) / fy_d
              P3D.z = depth(x_d,y_d)
              */
              var p3dx = (dx - cameraParams.d.cx) * dz / cameraParams.d.fx;
              var p3dy = (dy - cameraParams.d.cy) * dz / cameraParams.d.fy;
              var rx = cameraParams.r.r11 * p3dx - cameraParams.r.r12 * p3dy + cameraParams.r.r13 * dz + cameraParams.t.x;
              var ry = cameraParams.r.r21 * p3dx - cameraParams.r.r22 * p3dy + cameraParams.r.r23 * dz + cameraParams.t.y;
              var rz = cameraParams.r.r31 * p3dx - cameraParams.r.r32 * p3dy + cameraParams.r.r33 * dz + cameraParams.t.z;
              /*
              P2D_rgb.x = (P3D'.x * fx_rgb / P3D'.z) + cx_rgb
              P2D_rgb.y = (P3D'.y * fy_rgb / P3D'.z) + cy_rgb
              */
              var rgbx = rx * cameraParams.rgb.fx / rz + cameraParams.rgb.cx;
              var rgby = ry * cameraParams.rgb.fy / rz + cameraParams.rgb.cy;
              var rgb_index = 4 * ((~~rgbx) + (~~rgby) * color_canvas.width);
              rgbdImageData.data[arr_index] = colorImageData.data[rgb_index];
              rgbdImageData.data[arr_index + 1] = colorImageData.data[rgb_index + 1];
              rgbdImageData.data[arr_index + 2] = colorImageData.data[rgb_index + 2];
              rgbdImageData.data[arr_index + 3] = 255;
          }
      }
      rgbd_context.putImageData(rgbdImageData, 0, 0);
  }

  function drawVideo() {
      if (depthVideo.readyState === depthVideo.HAVE_ENOUGH_DATA && rgbVideo.readyState === rgbVideo.HAVE_ENOUGH_DATA) {
          //depth_context.drawImage(depthVideo, 0, 0, depth_canvas.width, depth_canvas.height);
          caliberate();
        depth_texture.needsUpdate = true;
        color_texture.needsUpdate = true;
    }
    //if ( rgbVideo.readyState === rgbVideo.HAVE_ENOUGH_DATA ) {
     //   color_context.drawImage(rgbVideo, 0, 0, color_canvas.width, color_canvas.height);
    //    color_texture.needsUpdate = true;
    //}
  }

  function onDocumentMouseMove( event ) {
    mouse.x = ( event.clientX - window.innerWidth / 2 ) * 8;
    mouse.y = ( event.clientY - window.innerHeight / 2 ) * 8;
  }

  function animate() {
    animationId = requestAnimationFrame( animate );

    render();
    stats.update();
  }

  function render() {
    camera.position.x += ( mouse.x - camera.position.x ) * 0.05;
    camera.position.y += ( - mouse.y - camera.position.y ) * 0.05;
    camera.lookAt( center );

    renderer.render( scene, camera );
  }
}

</script>

</body>

</html>
